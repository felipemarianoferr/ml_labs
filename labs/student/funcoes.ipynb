{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_models(dic_models, X_train_val, y_train_val, X_test_val, y_test_val):\n",
    "    \"\"\"\n",
    "    Treina e avalia uma lista de modelos com base no RMSE.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - models: lista de modelos sklearn (instâncias já inicializadas)\n",
    "    - X_train_val, y_train_val: dados de treino/validação\n",
    "    - X_test_val, y_test_val: dados de teste\n",
    "    \n",
    "    Retorna:\n",
    "    - Um dicionário com os RMSE de cada modelo\n",
    "    \"\"\"\n",
    "    \n",
    "    for name, model in dic_models.values():\n",
    "        model.fit(X_train_val, y_train_val)  # Treina o modelo\n",
    "        y_pred = model.predict(X_test_val)   # Faz previsões\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_val, y_pred))  # Calcula RMSE\n",
    "        \n",
    "        model_name = name\n",
    "        print(f'{model_name} RMSE: {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "def cross_validate_models(dic_models, X_train, y_train, cv=3, scoring='neg_root_mean_squared_error', n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Executa cross-validation para uma lista de modelos e retorna o RMSE médio de cada um.\n",
    "\n",
    "    Parâmetros:\n",
    "    - models: lista de modelos sklearn (instâncias já inicializadas)\n",
    "    - X_train, y_train: dados de treino\n",
    "    - cv: número de folds na validação cruzada (padrão: 3)\n",
    "    - scoring: métrica de avaliação (padrão: 'neg_root_mean_squared_error' para RMSE)\n",
    "    - n_jobs: número de threads a serem usadas (-1 usa todos os núcleos disponíveis)\n",
    "\n",
    "    Retorna:\n",
    "    - Um dicionário com a média do RMSE para cada modelo\n",
    "    \"\"\"\n",
    "\n",
    "    for name, model in dic_models.values():\n",
    "        \n",
    "        scores = cross_val_score(\n",
    "            model,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=cv, \n",
    "            scoring=scoring, \n",
    "            n_jobs=n_jobs)\n",
    "        \n",
    "        scores = -scores  # Converte para valores positivos, pois a métrica vem negativa\n",
    "\n",
    "        model_name = name\n",
    "        print(f'{model_name} CV RMSE: {scores}, mean : {scores.mean():.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_score, recall_score, f1_score,\n",
    "    precision_recall_curve, roc_curve, auc\n",
    ")\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def evaluate_classification_models(dic_models, X_train, y_train, cv=3, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Avalia modelos de classificação binária com métricas diversas.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - models: lista de modelos sklearn (instâncias já inicializadas)\n",
    "    - X_train, y_train: dados de treino\n",
    "    - cv: número de folds para cross-validation (padrão: 3)\n",
    "    - n_jobs: número de threads para paralelismo (-1 usa todos os núcleos)\n",
    "    \n",
    "    Retorna:\n",
    "    - Um dicionário com as métricas de cada modelo\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    for name, model in dic_models:\n",
    "        model_name = name\n",
    "        print(f\"\\n### Avaliando {model_name} ###\")\n",
    "\n",
    "        # Treina e calcula acurácia com cross-validation\n",
    "        accuracy_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"accuracy\", n_jobs=n_jobs)\n",
    "        accuracy_mean = accuracy_scores.mean()\n",
    "        print(f\"Acurácia: {accuracy_mean:.4f}\")\n",
    "\n",
    "        # Predições para matriz de confusão\n",
    "        y_train_pred = cross_val_predict(model, X_train, y_train, cv=cv, n_jobs=n_jobs)\n",
    "\n",
    "        # Matriz de Confusão\n",
    "        conf_matrix = confusion_matrix(y_train, y_train_pred)\n",
    "        print(\"Matriz de Confusão:\\n\", conf_matrix)\n",
    "\n",
    "        # Precision, Recall e F1-score\n",
    "        precision = precision_score(y_train, y_train_pred)\n",
    "        recall = recall_score(y_train, y_train_pred)\n",
    "        f1 = f1_score(y_train, y_train_pred)\n",
    "\n",
    "        print(f\"Precisão: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "        results[model_name] = {\n",
    "            \"accuracy\": accuracy_mean,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1\n",
    "        }\n",
    "        \n",
    "    return results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
